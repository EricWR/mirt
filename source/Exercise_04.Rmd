Exercise 4
========================================================

This exercise requires setting up `mixedmirt()` for estimating mixed effect models. 
The data is available in the `Exercise_04.Rdata` file. 

Load the dataset into R using the `load()` function, and inspect the defined objects.
The object named `data` represents a 15-item dichtomously scored test, while the `covdata` object
contains four person level covariates: Gender, percentage mark at midterm in math (midterm_Math) and
Science (midterm_Science), and which school number the subjects were sampled from (50 schools in total).

```{r setup, include=FALSE}
# set to true to show my answers
showcode <- TRUE
```

### 1) The data were simulated from a 2-factor correlated simple structure factor pattern (imagine this was your *a priori* theory....). Recover the pattern using exploratory methods, and create a `mirt.model()` object to be used for later analysis.  

```{r Q1, include=showcode, eval=showcode, tidy=FALSE}
library(mirt)
load('Exercise_04.Rdata')

mod <- mirt(data, 2)
summary(mod, suppress = .2)

model <- mirt.model('F1 = 1-7
                     F2 = 8-15
                     COV = F1*F2')
```

### 2) Determine if the model you obtained from 1) can be reasonably constrained to be fit by a confirmatory 2PL or Rasch model (i.e., all slopes equal to 1). For both models, use the MH-RM algorithm (`method = 'MHRM`). If possible, define an appropriate `mirtCluster()` to estimate the Monte Carlo log-likelihood faster.

```{r Q2, include=showcode, eval=showcode}
mirtCluster()
cmod.2PL <- mirt(data, model, method = 'MHRM', verbose = FALSE)
cmod.rasch <- mirt(data, model, itemtype = 'Rasch', method = 'MHRM', verbose = FALSE)
anova(cmod.2PL, cmod.rasch)
```

### 3) Using either the 2PL or Rasch model, estimate whether the expected response probabilities could be predicted by `Gender`, `midterm_Math`, and `midterm_Science`. Use `Gender` only in fitting one model, and all three covariates when fitting another. Inspect the coefficients using `summary()` and `coef()`. 

### Do these models fit better than the unconditional model; does the model containing all three predictors fit better than the model containing only `Gender`? Note: don't forget the ` ~ + 0 + items` in `fixed = `for including the item intercepts!

```{r Q3, include=showcode, eval=showcode}
head(covdata)
summary(covdata)

#for numerical stability it's often better to rescale continuous variables to fall between 10 to -10
covdata$midterm_Math <- (covdata$midterm_Math - mean(covdata$midterm_Math))/10
covdata$midterm_Science <- (covdata$midterm_Science - mean(covdata$midterm_Science))/10

mod1 <- mixedmirt(data, covdata, model=model, 
                  fixed = ~ 0 + items + Gender, verbose = FALSE)
summary(mod1)
coef(mod1)
anova(mod1, cmod.rasch)

mod3 <- mixedmirt(data, covdata, model=model, 
                  fixed = ~ 0 + items + Gender + midterm_Math + midterm_Science, verbose = FALSE)
summary(mod3)
coef(mod3)
anova(mod1, mod3)
```

### 4) Finally, include the `school` predictor variable in the model containing the other three covariates. Given that `school` has 50 unique values, it may be beneficial to treat the variable as a 'random' so that instead of estimating 49 fixed effect coefficients we can estimate only one variance effect. This can add better stability to the model, while still determining if there is any variability in the responses due to which school the subjects are from. Is there any substantial variability due to `school`?

```{r Q4, include=showcode, eval=showcode}
rmod3 <- mixedmirt(data, covdata, model=model, random = ~ 1|school,
                  fixed = ~ 0 + items + Gender + midterm_Math + midterm_Science, verbose = FALSE)
summary(rmod3)
```
