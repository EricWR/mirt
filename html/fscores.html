<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Compute factor score estimates (a.k.a, ability estimates,...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for fscores {mirt}"><tr><td>fscores {mirt}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc)</h2>

<h3>Description</h3>

<p>Computes MAP, EAP, ML (Embretson &amp; Reise, 2000), EAP for sum-scores (Thissen et al., 1995),
or WLE (Warm, 1989) factor scores with a multivariate normal
prior distribution using equally spaced quadrature. EAP scores for models with more than
three factors are generally not recommended since the integration grid becomes very large,
resulting in slower estimation and less precision if the <code>quadpts</code> are too low.
Therefore, MAP scores should be used instead of EAP scores for higher dimensional models.
Multiple imputation variants are possible for each estimator if a parameter
information matrix was computed, which are useful if the sample size/number of items were small.
As well, if the model contained latent regression predictors this information will
be used in computing MAP and EAP estimates (for these models, <code>full.scores=TRUE</code>
will always be used). Finally, plausible value imputation is also available, and will also account
for latent regression predictor effects.
</p>


<h3>Usage</h3>

<pre>
fscores(object, rotate = "oblimin", Target = NULL, full.scores = TRUE,
  method = "EAP", quadpts = NULL, response.pattern = NULL,
  plausible.draws = 0, returnER = FALSE, return.acov = FALSE,
  mean = NULL, cov = NULL, verbose = TRUE, full.scores.SE = FALSE,
  theta_lim = c(-6, 6), MI = 0, QMC = FALSE, custom_den = NULL,
  custom_theta = NULL, min_expected = 1, converge_info = FALSE, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>object</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>DiscreteClass</code></p>
</td></tr>
<tr valign="top"><td><code>rotate</code></td>
<td>
<p>prior rotation to be used when estimating the factor scores. See
<code><a href="summary-method.html">summary-method</a></code> for details. If the object is not an exploratory model
then this argument is ignored</p>
</td></tr>
<tr valign="top"><td><code>Target</code></td>
<td>
<p>target rotation; see <code><a href="summary-method.html">summary-method</a></code> for details</p>
</td></tr>
<tr valign="top"><td><code>full.scores</code></td>
<td>
<p>if <code>FALSE</code> then a summary table with
factor scores for each unique pattern is displayed. Otherwise, a matrix of factor scores
for each response pattern in the data is returned (default)</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>type of factor score estimation method. Can be expected
a-posteriori (<code>"EAP"</code>), Bayes modal (<code>"MAP"</code>), weighted likelihood estimation
(<code>"WLE"</code>), maximum likelihood (<code>"ML"</code>), or expected a-posteriori for sum scores
(<code>"EAPsum"</code>). Can also be <code>"plausible"</code> for a single plausible value imputation for
each case, and this is equivalent to setting <code>plausible.draws = 1</code></p>
</td></tr>
<tr valign="top"><td><code>quadpts</code></td>
<td>
<p>number of quadratures to use per dimension. If not specified, a suitable
one will be created which decreases as the number of dimensions increases
(and therefore for estimates such as EAP, will be less accurate). This is determined from
the switch statement
<code>quadpts &lt;- switch(as.character(nfact), '1'=61, '2'=31, '3'=15, '4'=9, '5'=7, 3)</code></p>
</td></tr>
<tr valign="top"><td><code>response.pattern</code></td>
<td>
<p>an optional argument used to calculate the factor scores and standard
errors for a given response vector or matrix/data.frame</p>
</td></tr>
<tr valign="top"><td><code>plausible.draws</code></td>
<td>
<p>number of plausible values to draw for future researchers
to perform secondary analyses of the latent trait scores. Typically used in conjunction
with latent regression predictors (see <code><a href="mirt.html">mirt</a></code> for details), but can
also be generated when no predictor variables were modeled. If <code>plausible.draws</code>
is greater than 0 a list of plausible values will be returned</p>
</td></tr>
<tr valign="top"><td><code>returnER</code></td>
<td>
<p>logical; return empirical reliability (also known as marginal reliability)
estimates as a numeric values?</p>
</td></tr>
<tr valign="top"><td><code>return.acov</code></td>
<td>
<p>logical; return a list containing covariance matrices instead of factors
scores? <code>impute = TRUE</code> not supported with this option</p>
</td></tr>
<tr valign="top"><td><code>mean</code></td>
<td>
<p>a vector for custom latent variable means. If NULL, the default for 'group' values
from the computed mirt object will be used</p>
</td></tr>
<tr valign="top"><td><code>cov</code></td>
<td>
<p>a custom matrix of the latent variable covariance matrix. If NULL, the default for
'group' values from the computed mirt object will be used</p>
</td></tr>
<tr valign="top"><td><code>verbose</code></td>
<td>
<p>logical; print verbose output messages?</p>
</td></tr>
<tr valign="top"><td><code>full.scores.SE</code></td>
<td>
<p>logical; when <code>full.scores == TRUE</code>, also return the
standard errors associated with each respondent? Default is <code>FALSE</code></p>
</td></tr>
<tr valign="top"><td><code>theta_lim</code></td>
<td>
<p>lower and upper range to evaluate latent trait integral for each dimension. If
omitted, a range will be generated automatically based on the number of dimensions</p>
</td></tr>
<tr valign="top"><td><code>MI</code></td>
<td>
<p>a number indicating how many multiple imputation draws to perform. Default is 0,
indicating that no MI draws will be performed</p>
</td></tr>
<tr valign="top"><td><code>QMC</code></td>
<td>
<p>logical; use quasi-Monte Carlo integration? If <code>quadpts</code> is omitted the
default number of nodes is 15000</p>
</td></tr>
<tr valign="top"><td><code>custom_den</code></td>
<td>
<p>a function used to define the integration density (if required). The NULL default
assumes that the multivariate normal distribution with the 'GroupPars' hyper-parameters are
used. At the minimum must be of the form:
</p>
<p><code>function(Theta, ...)</code>
</p>
<p>where Theta is a matrix of latent trait values (will be a grid of values
if <code>method == 'EAPsum'</code> or <code>method == 'EAP'</code>, otherwise Theta will have only 1 row).
Additional arguments may included and are caught through the <code>fscores(...)</code> input. The
function <em>must</em> return a numeric vector of density weights (one for each row in Theta)</p>
</td></tr>
<tr valign="top"><td><code>custom_theta</code></td>
<td>
<p>a matrix of custom integration nodes to use instead of the default, where
each column corresponds to the respective dimension in the model</p>
</td></tr>
<tr valign="top"><td><code>min_expected</code></td>
<td>
<p>when computing goodness of fit tests when <code>method = 'EAPsum'</code>, this value is used
to collapse across the conditioned total scores until the expected values are greater than this value. Note
that this only affect the goodness of fit tests and not the returned EAP for sum scores table</p>
</td></tr>
<tr valign="top"><td><code>converge_info</code></td>
<td>
<p>logical; include a column in the return objects containing a logical for each
response pattern indicating whether a maximum value was found (not relavent non-iterative methods,
such as EAP and EAPsum). Value is a reflection of the <code>code</code> element from <code><a href="../../stats/html/nlm.html">nlm</a></code>
(e.g., 1 indicates convergence)</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional arguments to be passed to <code>nlm</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will return either a table with the computed scores and standard errors,
the original data matrix with scores appended to the rightmost column, or the scores only. By
default the latent means and covariances are determined from the estimated object,
though these can be overwritten. Iterative estimation methods can be estimated
in parallel to decrease estimation times if a <code><a href="mirtCluster.html">mirtCluster</a></code> object is available.
</p>
<p>If the input object is a discrete latent class object estimated from <code><a href="mdirt.html">mdirt</a></code>
then the returned results will be with respect to the posterior classification for each
individual. The method inputs for <code>'DiscreteClass'</code> objects may only be <code>'EAP'</code>,
for posterior classification of each response pattern, or <code>'EAPsum'</code> for posterior
classification based on the raw sum-score.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Embretson, S. E. &amp; Reise, S. P. (2000). Item Response Theory for Psychologists. Erlbaum.
</p>
<p>Thissen, D., Pommerich, M., Billeaud, K., &amp; Williams, V. S. L. (1995).
Item Response Theory for Scores on Tests Including Polytomous Items with Ordered Responses.
<em>Applied Psychological Measurement, 19</em>, 39-49.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory.
<em>Psychometrika, 54</em>, 427-450.
</p>


<h3>See Also</h3>

<p><code><a href="averageMI.html">averageMI</a></code>
</p>


<h3>Examples</h3>

<pre><code class="r">## No test: 

mod &lt;- mirt(Science, 1)
tabscores &lt;- fscores(mod, full.scores = FALSE)
</code></pre>

<pre><code>## 
## Method:  EAP
## 
## Empirical Reliability:
## 
##     F1 
## 0.6666
</code></pre>

<pre><code class="r">head(tabscores)
</code></pre>

<pre><code>##      Comfort Work Future Benefit      F1  SE_F1
## [1,]       1    1      1       1 -2.7493 0.6294
## [2,]       1    3      2       1 -1.4198 0.5772
## [3,]       1    4      2       3 -0.7142 0.6200
## [4,]       1    4      3       1 -0.4469 0.6510
## [5,]       2    1      1       1 -2.5438 0.5909
## [6,]       2    1      2       4 -1.2479 0.5840
</code></pre>

<pre><code class="r">fullscores &lt;- fscores(mod)
fullscores_with_SE &lt;- fscores(mod, full.scores.SE=TRUE)
head(fullscores)
</code></pre>

<pre><code>##              F1
## [1,]  0.4015613
## [2,]  0.0520324
## [3,] -0.8906436
## [4,] -0.8906436
## [5,]  0.7653806
## [6,]  0.6695350
</code></pre>

<pre><code class="r">head(fullscores_with_SE)
</code></pre>

<pre><code>##              F1     SE_F1
## [1,]  0.4015613 0.5978747
## [2,]  0.0520324 0.5549554
## [3,] -0.8906436 0.5421855
## [4,] -0.8906436 0.5421855
## [5,]  0.7653806 0.6385998
## [6,]  0.6695350 0.5761860
</code></pre>

<pre><code class="r">#change method argument to use MAP estimates
fullscores &lt;- fscores(mod, method=&#39;MAP&#39;)
head(fullscores)
</code></pre>

<pre><code>##               F1
## [1,]  0.42140793
## [2,]  0.05866659
## [3,] -0.91936052
## [4,] -0.91936052
## [5,]  0.79013884
## [6,]  0.68302194
</code></pre>

<pre><code class="r">#calculate MAP for a given response vector
fscores(mod, method=&#39;MAP&#39;, response.pattern = c(1,2,3,4))
</code></pre>

<pre><code>##      Comfort Work Future Benefit         F1     SE_F1
## [1,]       1    2      3       4 -0.3704194 0.6054169
</code></pre>

<pre><code class="r">#or matrix
fscores(mod, method=&#39;MAP&#39;, response.pattern = rbind(c(1,2,3,4), c(2,2,1,3)))
</code></pre>

<pre><code>##      Comfort Work Future Benefit         F1     SE_F1
## [1,]       1    2      3       4 -0.3704194 0.6054169
## [2,]       2    2      1       3 -1.6937559 0.5773972
</code></pre>

<pre><code class="r">#use custom latent variable properties (diffuse prior for MAP is very close to ML)
fscores(mod, method=&#39;MAP&#39;, cov = matrix(1000), full.scores = FALSE)
</code></pre>

<pre><code>## 
## Method:  MAP
## 
## Empirical Reliability:
## 
##     F1 
## 0.4207
</code></pre>

<pre><code>##       Comfort Work Future Benefit      F1   SE_F1
##  [1,]       1    1      1       1 -9.3395  9.6355
##  [2,]       1    3      2       1 -2.1040  0.6892
##  [3,]       1    4      2       3 -1.1508  0.7050
##  [4,]       1    4      3       1 -0.7810  0.8073
##  [5,]       2    1      1       1 -4.3941  1.1795
##  [6,]       2    1      2       4 -1.8628  0.6679
##  [7,]       2    2      1       1 -3.2477  0.8121
##  [8,]       2    2      2       2 -1.9114  0.5875
##  [9,]       2    2      2       3 -1.6056  0.6085
## [10,]       2    2      3       1 -1.4680  0.7137
## [11,]       2    2      3       2 -1.1683  0.6347
## [12,]       2    2      3       3 -0.7966  0.6390
## [13,]       2    2      4       3  0.2403  0.7887
## [14,]       2    3      1       3 -2.1424  0.7017
## [15,]       2    3      2       2 -1.6086  0.6258
## [16,]       2    3      2       3 -1.2540  0.6302
## [17,]       2    3      3       2 -0.7557  0.6559
## [18,]       2    3      3       3 -0.3316  0.6981
## [19,]       2    3      3       4  0.0830  0.7614
## [20,]       2    3      4       1  0.1890  0.8780
## [21,]       2    3      4       3  0.7627  0.6807
## [22,]       2    4      2       1 -1.8221  0.6942
## [23,]       2    4      4       3  1.3073  0.7535
## [24,]       2    4      4       4  2.0946  1.0392
## [25,]       3    1      1       1 -3.5381  1.0014
## [26,]       3    1      1       3 -2.5098  0.6972
## [27,]       3    1      2       2 -1.9255  0.6147
## [28,]       3    1      2       3 -1.5869  0.6434
## [29,]       3    1      3       2 -1.0875  0.6741
## [30,]       3    1      3       3 -0.6580  0.6955
## [31,]       3    1      3       4 -0.2808  0.8073
## [32,]       3    1      4       3  0.5425  0.7339
## [33,]       3    1      4       4  1.0379  0.7358
## [34,]       3    2      1       2 -2.3481  0.6247
## [35,]       3    2      1       4 -1.9130  0.7095
## [36,]       3    2      2       1 -1.8613  0.6158
## [37,]       3    2      2       2 -1.5767  0.5940
## [38,]       3    2      2       3 -1.2549  0.6023
## [39,]       3    2      3       1 -1.0252  0.6627
## [40,]       3    2      3       2 -0.7978  0.6290
## [41,]       3    2      3       3 -0.4089  0.6677
## [42,]       3    2      3       4 -0.0374  0.7438
## [43,]       3    2      4       1  0.0147  0.9004
## [44,]       3    2      4       2  0.2054  0.7886
## [45,]       3    2      4       3  0.6430  0.6841
## [46,]       3    2      4       4  1.1017  0.7184
## [47,]       3    3      1       3 -1.6293  0.7802
## [48,]       3    3      2       1 -1.5176  0.6591
## [49,]       3    3      2       2 -1.2391  0.6169
## [50,]       3    3      2       3 -0.8825  0.6301
## [51,]       3    3      2       4 -0.6208  0.7081
## [52,]       3    3      3       1 -0.5491  0.7107
## [53,]       3    3      3       2 -0.3474  0.6875
## [54,]       3    3      3       3  0.0864  0.6869
## [55,]       3    3      3       4  0.4902  0.6762
## [56,]       3    3      4       2  0.7324  0.6812
## [57,]       3    3      4       3  1.0478  0.6499
## [58,]       3    3      4       4  1.5247  0.7456
## [59,]       3    4      1       3 -1.3815  0.9427
## [60,]       3    4      2       3 -0.6084  0.7256
## [61,]       3    4      3       2  0.0993  0.7676
## [62,]       3    4      3       3  0.5379  0.6774
## [63,]       3    4      3       4  0.9612  0.6745
## [64,]       3    4      4       1  1.2181  0.7585
## [65,]       3    4      4       2  1.2720  0.7491
## [66,]       3    4      4       3  1.5993  0.7662
## [67,]       3    4      4       4  2.4224  1.0401
## [68,]       4    1      1       4 -2.1056  0.7724
## [69,]       4    1      2       2 -1.6380  0.6541
## [70,]       4    1      2       4 -1.0141  0.7239
## [71,]       4    1      3       4  0.3612  0.7777
## [72,]       4    2      2       1 -1.5678  0.6512
## [73,]       4    2      2       3 -0.9352  0.6276
## [74,]       4    2      3       3  0.0537  0.7108
## [75,]       4    2      3       4  0.4917  0.7095
## [76,]       4    2      4       2  0.7623  0.7230
## [77,]       4    2      4       4  1.7598  0.9306
## [78,]       4    3      2       3 -0.4851  0.7038
## [79,]       4    3      3       2  0.1391  0.7181
## [80,]       4    3      3       3  0.5327  0.6523
## [81,]       4    3      3       4  0.9290  0.6555
## [82,]       4    3      4       2  1.2156  0.7194
## [83,]       4    3      4       3  1.5265  0.7343
## [84,]       4    3      4       4  2.2584  0.9678
## [85,]       4    4      3       2  0.6397  0.7070
## [86,]       4    4      3       3  0.9811  0.6613
## [87,]       4    4      3       4  1.4646  0.7488
## [88,]       4    4      4       2  2.0278  1.0101
## [89,]       4    4      4       3  2.3899  1.0151
## [90,]       4    4      4       4  7.1119 10.6159
</code></pre>

<pre><code class="r">fscores(mod, method=&#39;ML&#39;, full.scores = FALSE)
</code></pre>

<pre><code>## 
## Method:  ML
## 
## Empirical Reliability:
## 
##    F1 
## 0.716
</code></pre>

<pre><code>##       Comfort Work Future Benefit      F1  SE_F1
##  [1,]       1    1      1       1    -Inf     NA
##  [2,]       1    3      2       1 -2.1050 0.6894
##  [3,]       1    4      2       3 -1.1514 0.7052
##  [4,]       1    4      3       1 -0.7815 0.8075
##  [5,]       2    1      1       1 -4.4002 1.1822
##  [6,]       2    1      2       4 -1.8637 0.6680
##  [7,]       2    2      1       1 -3.2498 0.8130
##  [8,]       2    2      2       2 -1.9120 0.5876
##  [9,]       2    2      2       3 -1.6062 0.6086
## [10,]       2    2      3       1 -1.4687 0.7140
## [11,]       2    2      3       2 -1.1688 0.6349
## [12,]       2    2      3       3 -0.7969 0.6391
## [13,]       2    2      4       3  0.2404 0.7889
## [14,]       2    3      1       3 -2.1434 0.7018
## [15,]       2    3      2       2 -1.6092 0.6259
## [16,]       2    3      2       3 -1.2545 0.6303
## [17,]       2    3      3       2 -0.7560 0.6560
## [18,]       2    3      3       3 -0.3318 0.6983
## [19,]       2    3      3       4  0.0831 0.7616
## [20,]       2    3      4       1  0.1892 0.8783
## [21,]       2    3      4       3  0.7630 0.6808
## [22,]       2    4      2       1 -1.8230 0.6943
## [23,]       2    4      4       3  1.3080 0.7539
## [24,]       2    4      4       4  2.0968 1.0407
## [25,]       3    1      1       1 -3.5417 1.0035
## [26,]       3    1      1       3 -2.5110 0.6975
## [27,]       3    1      2       2 -1.9262 0.6148
## [28,]       3    1      2       3 -1.5875 0.6435
## [29,]       3    1      3       2 -1.0880 0.6743
## [30,]       3    1      3       3 -0.6583 0.6957
## [31,]       3    1      3       4 -0.2810 0.8076
## [32,]       3    1      4       3  0.5428 0.7340
## [33,]       3    1      4       4  1.0384 0.7361
## [34,]       3    2      1       2 -2.3490 0.6248
## [35,]       3    2      1       4 -1.9140 0.7095
## [36,]       3    2      2       1 -1.8620 0.6159
## [37,]       3    2      2       2 -1.5773 0.5941
## [38,]       3    2      2       3 -1.2554 0.6024
## [39,]       3    2      3       1 -1.0256 0.6629
## [40,]       3    2      3       2 -0.7981 0.6291
## [41,]       3    2      3       3 -0.4091 0.6678
## [42,]       3    2      3       4 -0.0374 0.7440
## [43,]       3    2      4       1  0.0147 0.9008
## [44,]       3    2      4       2  0.2055 0.7888
## [45,]       3    2      4       3  0.6433 0.6842
## [46,]       3    2      4       4  1.1023 0.7187
## [47,]       3    3      1       3 -1.6303 0.7802
## [48,]       3    3      2       1 -1.5183 0.6593
## [49,]       3    3      2       2 -1.2396 0.6170
## [50,]       3    3      2       3 -0.8828 0.6302
## [51,]       3    3      2       4 -0.6211 0.7082
## [52,]       3    3      3       1 -0.5494 0.7109
## [53,]       3    3      3       2 -0.3476 0.6876
## [54,]       3    3      3       3  0.0864 0.6870
## [55,]       3    3      3       4  0.4904 0.6763
## [56,]       3    3      4       2  0.7327 0.6813
## [57,]       3    3      4       3  1.0482 0.6501
## [58,]       3    3      4       4  1.5256 0.7460
## [59,]       3    4      1       3 -1.3827 0.9427
## [60,]       3    4      2       3 -0.6087 0.7257
## [61,]       3    4      3       2  0.0993 0.7678
## [62,]       3    4      3       3  0.5381 0.6775
## [63,]       3    4      3       4  0.9616 0.6747
## [64,]       3    4      4       1  1.2188 0.7588
## [65,]       3    4      4       2  1.2727 0.7494
## [66,]       3    4      4       3  1.6003 0.7667
## [67,]       3    4      4       4  2.4250 1.0417
## [68,]       4    1      1       4 -2.1068 0.7725
## [69,]       4    1      2       2 -1.6387 0.6542
## [70,]       4    1      2       4 -1.0146 0.7241
## [71,]       4    1      3       4  0.3614 0.7779
## [72,]       4    2      2       1 -1.5685 0.6514
## [73,]       4    2      2       3 -0.9355 0.6277
## [74,]       4    2      3       3  0.0537 0.7109
## [75,]       4    2      3       4  0.4920 0.7097
## [76,]       4    2      4       2  0.7627 0.7231
## [77,]       4    2      4       4  1.7614 0.9317
## [78,]       4    3      2       3 -0.4853 0.7039
## [79,]       4    3      3       2  0.1392 0.7183
## [80,]       4    3      3       3  0.5329 0.6524
## [81,]       4    3      3       4  0.9294 0.6556
## [82,]       4    3      4       2  1.2163 0.7197
## [83,]       4    3      4       3  1.5274 0.7347
## [84,]       4    3      4       4  2.2605 0.9690
## [85,]       4    4      3       2  0.6400 0.7071
## [86,]       4    4      3       3  0.9816 0.6615
## [87,]       4    4      3       4  1.4654 0.7492
## [88,]       4    4      4       2  2.0298 1.0115
## [89,]       4    4      4       3  2.3923 1.0165
## [90,]       4    4      4       4     Inf     NA
</code></pre>

<pre><code class="r"># EAPsum table of values based on total scores
fscores(mod, method = &#39;EAPsum&#39;, full.scores = FALSE)
</code></pre>

<pre><code>##       df       X2       p.X2 rxx_Theta.1
## stats 10 16.31202 0.09104204   0.6241528
</code></pre>

<pre><code>##    Sum.Scores       Theta  SE.Theta observed   expected
## 4           4 -2.74926868 0.6293569        2  0.1241449
## 5           5 -2.43096708 0.6167669        1  0.7902670
## 6           6 -2.08095804 0.6101826        2  2.7598787
## 7           7 -1.71797996 0.6019326        1  7.2515944
## 8           8 -1.36354348 0.5979810       11 15.8925644
## 9           9 -1.01186764 0.6038596       32 29.6740255
## 10         10 -0.64926712 0.6101301       58 48.3632492
## 11         11 -0.28688279 0.6048405       70 68.4845962
## 12         12  0.08240446 0.5996636       91 80.5530280
## 13         13  0.48709473 0.6133534       56 65.6680929
## 14         14  0.93406958 0.6170256       36 42.6372130
## 15         15  1.38421709 0.6218261       20 22.3313442
## 16         16  1.85351394 0.6544099       12  7.4700016
</code></pre>

<pre><code class="r">#WLE estimation, run in parallel using available cores
mirtCluster()
</code></pre>

<pre><code>## mirtCluster() has already been defined
</code></pre>

<pre><code class="r">fscores(mod, method=&#39;WLE&#39;, full.scores = FALSE)
</code></pre>

<pre><code>## 
## Method:  WLE
## 
## Empirical Reliability:
## 
##     F1 
## 0.7513
</code></pre>

<pre><code>##       Comfort Work Future Benefit      F1  SE_F1
##  [1,]       1    1      1       1 -5.6981 1.5783
##  [2,]       1    3      2       1 -2.1191 0.6333
##  [3,]       1    4      2       3 -1.1388 0.6557
##  [4,]       1    4      3       1 -0.8489 0.7000
##  [5,]       2    1      1       1 -4.0112 1.1424
##  [6,]       2    1      2       4 -1.8957 0.6698
##  [7,]       2    2      1       1 -3.0123 0.7172
##  [8,]       2    2      2       2 -1.9367 0.5816
##  [9,]       2    2      2       3 -1.6086 0.6503
## [10,]       2    2      3       1 -1.4484 0.7524
## [11,]       2    2      3       2 -1.1564 0.6003
## [12,]       2    2      3       3 -0.8409 0.5821
## [13,]       2    2      4       3  0.3550 0.7928
## [14,]       2    3      1       3 -2.1514 0.6360
## [15,]       2    3      2       2 -1.6123 0.6717
## [16,]       2    3      2       3 -1.2353 0.6115
## [17,]       2    3      3       2 -0.8088 0.5960
## [18,]       2    3      3       3 -0.4278 0.7156
## [19,]       2    3      3       4  0.1531 0.9074
## [20,]       2    3      4       1  0.3248 0.8937
## [21,]       2    3      4       3  0.7863 0.5970
## [22,]       2    4      2       1 -1.8565 0.7086
## [23,]       2    4      4       3  1.1908 0.6439
## [24,]       2    4      4       4  1.7593 0.8989
## [25,]       3    1      1       1 -3.1951 0.8594
## [26,]       3    1      1       3 -2.4395 0.6038
## [27,]       3    1      2       2 -1.9528 0.6042
## [28,]       3    1      2       3 -1.5874 0.6929
## [29,]       3    1      3       2 -1.0851 0.6217
## [30,]       3    1      3       3 -0.7331 0.6314
## [31,]       3    1      3       4 -0.4062 0.8478
## [32,]       3    1      4       3  0.6185 0.6509
## [33,]       3    1      4       4  0.9906 0.6266
## [34,]       3    2      1       2 -2.3201 0.5609
## [35,]       3    2      1       4 -1.9492 0.6902
## [36,]       3    2      2       1 -1.8892 0.6194
## [37,]       3    2      2       2 -1.5758 0.6318
## [38,]       3    2      2       3 -1.2377 0.5865
## [39,]       3    2      3       1 -1.0324 0.6067
## [40,]       3    2      3       2 -0.8407 0.5744
## [41,]       3    2      3       3 -0.4995 0.6581
## [42,]       3    2      3       4 -0.0389 0.9527
## [43,]       3    2      4       1  0.0741 1.2538
## [44,]       3    2      4       2  0.3167 0.8182
## [45,]       3    2      4       3  0.6928 0.6078
## [46,]       3    2      4       4  1.0401 0.6153
## [47,]       3    3      1       3 -1.6409 0.8706
## [48,]       3    3      2       1 -1.5072 0.7037
## [49,]       3    3      2       2 -1.2221 0.5969
## [50,]       3    3      2       3 -0.9118 0.5744
## [51,]       3    3      2       4 -0.7033 0.6405
## [52,]       3    3      3       1 -0.6422 0.6582
## [53,]       3    3      3       2 -0.4415 0.6982
## [54,]       3    3      3       3  0.1402 0.7952
## [55,]       3    3      3       4  0.5645 0.6216
## [56,]       3    3      4       2  0.7628 0.5991
## [57,]       3    3      4       3  1.0064 0.5714
## [58,]       3    3      4       4  1.3703 0.6562
## [59,]       3    4      1       3 -1.3334 0.9717
## [60,]       3    4      2       3 -0.6960 0.6536
## [61,]       3    4      3       2  0.1778 0.8996
## [62,]       3    4      3       3  0.6055 0.6145
## [63,]       3    4      3       4  0.9377 0.5880
## [64,]       3    4      4       1  1.1212 0.6436
## [65,]       3    4      4       2  1.1644 0.6391
## [66,]       3    4      4       3  1.4275 0.6769
## [67,]       3    4      4       4  2.0826 0.9251
## [68,]       4    1      1       4 -2.1235 0.6928
## [69,]       4    1      2       2 -1.6470 0.7059
## [70,]       4    1      2       4 -1.0245 0.6510
## [71,]       4    1      3       4  0.4718 0.7257
## [72,]       4    2      2       1 -1.5652 0.7013
## [73,]       4    2      2       3 -0.9557 0.5738
## [74,]       4    2      3       3  0.0994 0.8541
## [75,]       4    2      3       4  0.5723 0.6466
## [76,]       4    2      4       2  0.7882 0.6254
## [77,]       4    2      4       4  1.5072 0.7763
## [78,]       4    3      2       3 -0.5816 0.6611
## [79,]       4    3      3       2  0.2172 0.8036
## [80,]       4    3      3       3  0.5971 0.5982
## [81,]       4    3      3       4  0.9140 0.5753
## [82,]       4    3      4       2  1.1268 0.6184
## [83,]       4    3      4       3  1.3757 0.6487
## [84,]       4    3      4       4  1.9591 0.8737
## [85,]       4    4      3       2  0.6928 0.6233
## [86,]       4    4      3       3  0.9538 0.5790
## [87,]       4    4      3       4  1.3184 0.6535
## [88,]       4    4      4       2  1.7123 0.8685
## [89,]       4    4      4       3  2.0648 0.9070
## [90,]       4    4      4       4  3.3081 1.3470
</code></pre>

<pre><code class="r">#multiple imputation using 30 draws for EAP scores. Requires information matrix
mod &lt;- mirt(Science, 1, SE=TRUE)
fscores(mod, MI = 30)
</code></pre>

<pre><code>##                  F1
##   [1,]  0.404562769
##   [2,]  0.047566868
##   [3,] -0.884184262
##   [4,] -0.884184262
##   [5,]  0.736529889
##   [6,]  0.677565513
##   [7,] -0.030981557
##   [8,] -0.030981557
##   [9,]  0.428127848
##  [10,]  0.350454850
##  [11,]  0.699266910
##  [12,] -1.106557813
##  [13,]  0.047566868
##  [14,] -0.230780448
##  [15,] -0.561117626
##  [16,]  0.047566868
##  [17,] -1.387437830
##  [18,]  0.047566868
##  [19,] -0.561117626
##  [20,]  0.047566868
##  [21,] -1.270423347
##  [22,] -0.444466483
##  [23,]  0.047566868
##  [24,] -0.686320651
##  [25,] -0.230780448
##  [26,] -0.561117626
##  [27,] -0.279001358
##  [28,]  0.350454850
##  [29,] -0.758649136
##  [30,] -0.279001358
##  [31,]  0.047566868
##  [32,] -0.854055561
##  [33,]  0.302977526
##  [34,]  0.314672137
##  [35,] -0.030981557
##  [36,]  0.022011344
##  [37,]  0.047566868
##  [38,]  0.047566868
##  [39,]  0.677565513
##  [40,] -1.137117431
##  [41,]  0.047566868
##  [42,]  0.066045120
##  [43,] -1.080532640
##  [44,] -0.561336079
##  [45,] -0.854055561
##  [46,]  0.785962813
##  [47,]  0.347069983
##  [48,] -2.180019010
##  [49,]  0.450918070
##  [50,]  0.047566868
##  [51,]  0.699266910
##  [52,]  0.047566868
##  [53,]  0.699266910
##  [54,]  1.021119444
##  [55,]  1.021119444
##  [56,]  0.047566868
##  [57,] -0.561117626
##  [58,] -1.178285782
##  [59,]  0.639272803
##  [60,] -0.293035991
##  [61,]  0.428127848
##  [62,] -0.564860294
##  [63,]  0.350454850
##  [64,] -1.606289883
##  [65,]  0.047566868
##  [66,] -1.594110952
##  [67,] -1.150163709
##  [68,] -0.360539362
##  [69,] -0.854055561
##  [70,] -0.444466483
##  [71,] -0.715335373
##  [72,] -0.884184262
##  [73,]  1.846168703
##  [74,]  0.596002991
##  [75,] -0.030981557
##  [76,] -0.564860294
##  [77,] -0.230780448
##  [78,]  0.347069983
##  [79,] -0.279001358
##  [80,]  1.432950740
##  [81,] -0.279001358
##  [82,]  0.699266910
##  [83,]  1.381556250
##  [84,]  0.350454850
##  [85,]  0.423711448
##  [86,] -0.758649136
##  [87,]  0.046562422
##  [88,] -1.001321816
##  [89,]  0.428127848
##  [90,] -0.884184262
##  [91,] -0.444466483
##  [92,] -1.606289883
##  [93,] -0.003863254
##  [94,] -0.279001358
##  [95,]  1.222016164
##  [96,]  0.314672137
##  [97,] -0.758649136
##  [98,] -1.150163709
##  [99,]  0.347069983
## [100,] -0.854055561
## [101,]  0.046886004
## [102,]  0.022011344
## [103,]  0.653450399
## [104,]  1.004599436
## [105,]  0.314672137
## [106,]  0.022011344
## [107,] -1.156558409
## [108,]  1.432950740
## [109,]  0.047566868
## [110,] -1.428949731
## [111,]  0.055015839
## [112,] -1.150163709
## [113,] -0.561117626
## [114,]  0.047566868
## [115,] -0.230780448
## [116,] -0.230780448
## [117,] -0.230780448
## [118,]  1.846168703
## [119,]  1.381556250
## [120,]  0.699266910
## [121,]  1.846168703
## [122,]  0.428127848
## [123,]  0.047566868
## [124,] -0.230780448
## [125,]  1.066530606
## [126,] -1.253239053
## [127,] -0.584943096
## [128,] -0.854055561
## [129,] -1.150163709
## [130,] -1.032643709
## [131,]  0.047566868
## [132,]  0.047566868
## [133,] -0.279001358
## [134,]  0.690446195
## [135,]  1.381556250
## [136,] -0.360539362
## [137,]  0.184162380
## [138,] -0.561336079
## [139,]  1.021119444
## [140,] -0.279001358
## [141,]  0.022011344
## [142,]  1.381556250
## [143,] -0.279001358
## [144,] -0.230780448
## [145,]  0.047566868
## [146,] -1.106557813
## [147,] -0.511549468
## [148,] -0.854055561
## [149,]  1.433836596
## [150,] -0.511549468
## [151,] -0.360539362
## [152,]  1.381556250
## [153,] -1.150163709
## [154,]  0.047566868
## [155,] -0.561117626
## [156,] -0.230780448
## [157,]  1.433836596
## [158,]  0.047566868
## [159,]  0.450918070
## [160,] -0.279001358
## [161,]  0.022011344
## [162,] -1.150163709
## [163,] -0.561336079
## [164,] -1.387437830
## [165,] -1.070126335
## [166,] -0.279001358
## [167,] -0.230780448
## [168,] -0.279001358
## [169,] -0.852387540
## [170,]  1.432950740
## [171,] -0.883704885
## [172,]  0.350454850
## [173,] -0.854055561
## [174,]  1.381556250
## [175,]  0.639272803
## [176,]  1.031832642
## [177,]  0.350454850
## [178,] -0.561336079
## [179,]  0.047566868
## [180,] -0.883704885
## [181,]  1.432950740
## [182,]  0.350454850
## [183,] -0.604142422
## [184,]  0.047566868
## [185,] -0.854055561
## [186,] -0.230780448
## [187,]  0.350454850
## [188,]  0.047566868
## [189,] -0.183643411
## [190,]  0.785962813
## [191,] -0.216302200
## [192,]  1.075392426
## [193,] -0.561336079
## [194,]  1.432950740
## [195,] -1.150163709
## [196,]  0.699266910
## [197,] -1.410935088
## [198,] -0.553017581
## [199,]  0.699266910
## [200,] -0.854055561
## [201,]  1.846168703
## [202,]  1.031832642
## [203,]  1.021119444
## [204,]  0.047566868
## [205,] -0.561117626
## [206,]  1.846168703
## [207,]  0.055015839
## [208,] -1.150163709
## [209,]  0.314672137
## [210,] -1.156558409
## [211,]  1.381556250
## [212,]  0.350454850
## [213,] -0.604142422
## [214,]  0.022011344
## [215,]  0.047566868
## [216,] -0.279001358
## [217,] -1.022909131
## [218,]  0.047566868
## [219,]  1.066530606
## [220,]  0.047566868
## [221,] -0.030981557
## [222,]  1.004599436
## [223,]  0.314672137
## [224,] -0.854055561
## [225,] -0.561336079
## [226,]  0.350454850
## [227,] -0.561117626
## [228,]  0.639272803
## [229,] -0.444466483
## [230,] -0.230780448
## [231,]  0.314672137
## [232,] -1.106557813
## [233,]  0.022011344
## [234,]  0.699266910
## [235,] -1.150163709
## [236,]  1.021119444
## [237,]  0.350454850
## [238,] -0.230780448
## [239,]  0.047566868
## [240,]  0.047566868
## [241,]  0.047566868
## [242,]  0.350454850
## [243,] -0.216302200
## [244,] -0.854055561
## [245,]  1.021119444
## [246,]  1.066530606
## [247,]  0.361502332
## [248,]  0.047566868
## [249,]  0.046562422
## [250,]  0.350454850
## [251,] -0.279001358
## [252,] -0.561117626
## [253,] -0.314290101
## [254,] -0.230780448
## [255,]  0.350454850
## [256,]  0.428127848
## [257,] -0.230780448
## [258,] -0.561117626
## [259,]  0.350454850
## [260,] -0.230780448
## [261,] -0.279001358
## [262,]  0.350454850
## [263,]  1.202454204
## [264,]  0.808618157
## [265,]  0.834673588
## [266,]  0.047566868
## [267,]  0.653450399
## [268,]  0.302977526
## [269,] -1.131303201
## [270,] -1.410935088
## [271,] -0.279001358
## [272,] -0.183643411
## [273,]  0.690446195
## [274,]  0.699266910
## [275,]  1.846168703
## [276,]  0.047566868
## [277,] -0.758649136
## [278,]  0.047566868
## [279,]  0.350454850
## [280,]  1.066530606
## [281,]  1.031832642
## [282,] -0.279001358
## [283,]  0.047566868
## [284,]  0.047566868
## [285,]  1.433836596
## [286,]  1.021119444
## [287,] -1.410935088
## [288,] -1.410935088
## [289,]  1.846168703
## [290,] -0.279001358
## [291,]  0.047566868
## [292,]  0.047566868
## [293,] -1.137117431
## [294,] -0.230780448
## [295,]  0.078664941
## [296,] -0.561336079
## [297,] -0.279001358
## [298,] -0.884184262
## [299,] -0.230780448
## [300,]  1.202454204
## [301,]  0.699266910
## [302,] -0.279001358
## [303,] -1.106557813
## [304,]  0.047566868
## [305,] -0.230780448
## [306,]  0.047566868
## [307,]  0.361502332
## [308,] -0.183643411
## [309,]  0.699266910
## [310,]  1.031832642
## [311,] -0.854055561
## [312,]  1.066530606
## [313,] -0.561117626
## [314,]  0.047566868
## [315,] -0.360539362
## [316,]  0.653450399
## [317,]  0.699266910
## [318,]  0.834673588
## [319,] -0.091047134
## [320,]  0.047566868
## [321,] -0.230780448
## [322,] -1.150163709
## [323,]  0.428127848
## [324,]  0.047566868
## [325,]  0.350454850
## [326,] -0.230780448
## [327,] -0.561117626
## [328,] -0.279001358
## [329,]  0.653450399
## [330,]  1.381556250
## [331,]  1.021119444
## [332,] -0.561336079
## [333,] -0.230780448
## [334,]  1.021119444
## [335,]  1.066530606
## [336,]  1.004599436
## [337,] -2.226229161
## [338,] -0.854055561
## [339,] -0.561117626
## [340,]  0.047566868
## [341,] -0.216302200
## [342,] -0.561336079
## [343,] -0.561117626
## [344,]  0.699266910
## [345,]  0.022011344
## [346,]  1.021119444
## [347,]  0.428127848
## [348,]  0.350454850
## [349,] -0.279001358
## [350,] -0.241896221
## [351,] -0.884184262
## [352,]  0.047566868
## [353,] -0.561336079
## [354,] -0.444466483
## [355,] -0.511549468
## [356,] -0.230780448
## [357,] -0.462224617
## [358,] -0.604142422
## [359,] -2.766114602
## [360,]  0.361502332
## [361,] -0.884184262
## [362,]  0.314672137
## [363,]  1.031832642
## [364,] -0.279001358
## [365,]  0.350454850
## [366,]  0.078664941
## [367,]  0.047566868
## [368,]  0.047566868
## [369,]  0.047566868
## [370,]  1.846168703
## [371,]  0.047566868
## [372,]  0.314672137
## [373,]  0.347069983
## [374,]  1.432950740
## [375,]  1.846168703
## [376,]  0.047566868
## [377,] -2.766114602
## [378,]  1.846168703
## [379,]  0.239019905
## [380,]  0.350454850
## [381,] -0.561117626
## [382,]  1.846168703
## [383,] -1.336649414
## [384,] -0.840352936
## [385,]  1.021119444
## [386,]  1.846168703
## [387,]  1.021119444
## [388,] -0.758649136
## [389,] -0.561117626
## [390,] -2.554776056
## [391,] -0.314290101
## [392,] -0.360539362
</code></pre>

<pre><code class="r"># plausible values for future work
pv &lt;- fscores(mod, plausible.draws = 5)
lapply(pv, function(x) c(mean=mean(x), var=var(x), min=min(x), max=max(x)))
</code></pre>

<pre><code>## [[1]]
##         mean          var          min          max 
## -0.009577833  1.044736305 -3.279078964  2.888995420 
## 
## [[2]]
##         mean          var          min          max 
## -0.006662328  0.909259867 -2.876890944  3.332078741 
## 
## [[3]]
##        mean         var         min         max 
##  0.01277496  1.05337118 -3.28109443  2.67817741 
## 
## [[4]]
##        mean         var         min         max 
##  0.01749199  0.94332608 -2.98641103  2.47678873 
## 
## [[5]]
##        mean         var         min         max 
## -0.02412937  0.99838643 -3.12937288  2.88508346
</code></pre>

<pre><code class="r">## define a custom_den function. EAP with a uniform prior between -3 and 3
fun &lt;- function(Theta, ...) as.numeric(dunif(Theta, min = -3, max = 3))
head(fscores(mod, custom_den = fun))
</code></pre>

<pre><code>##               F1
## [1,]  0.62811597
## [2,]  0.07362511
## [3,] -1.23497086
## [4,] -1.23497086
## [5,]  1.25827841
## [6,]  1.00860231
</code></pre>

<pre><code class="r"># custom MAP prior: standard truncated normal between 5 and -2
library(msm)
# need the :: scope for parallel to see the function (not require if no mirtCluster() defined)
fun &lt;- function(Theta, ...) msm::dtnorm(Theta, mean = 0, sd = 1, lower = -2, upper = 5)
head(fscores(mod, custom_den = fun, method = &#39;MAP&#39;, full.scores = FALSE))
</code></pre>

<pre><code>## 
## Method:  MAP
## 
## Empirical Reliability:
## 
##     F1 
## 0.6637
</code></pre>

<pre><code>##      Comfort Work Future Benefit      F1  SE_F1
## [1,]       1    1      1       1 -2.0000 0.5956
## [2,]       1    3      2       1 -1.4235 0.5681
## [3,]       1    4      2       3 -0.7628 0.5921
## [4,]       1    4      3       1 -0.4621 0.6529
## [5,]       2    1      1       1 -2.0000 0.5707
## [6,]       2    1      2       4 -1.2729 0.5680
</code></pre>

<pre><code class="r">## End(No test)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>mirt</em> version 1.14 <a href="00Index.html">Index</a>]</div>
</body></html>
